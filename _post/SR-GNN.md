# Session-based Recommendation with Graph Neural Networks



## 背景

​	大多数现有的推荐系统都假定用户画像和历史行为被全部记录，但在很多情况下，用户的身份是未知的，且只能获取正在进行的会话中的用户的历史行为。

​	现有的基于会话的推荐模型有以下缺点：

* 会话大多是匿名的且数量众多，而会话中点击所涉及的用户行为往往是有限的，很难预估用户表示。

* 一般是对连续商品的单项转换进行建模并用作局部因素，忽略了上下文之间的转换，致使距离较远的商品的复杂转换被忽略。

  为了克服这些限制，文中提出了基于会话的图卷积网络模型（SR-GNN），能够探索商品间丰富的转换并生成商品的潜在特征向量。
  
  

## SR-GNN模型

* **定向图**
  * 每个会话序列都被建模为一个定向图，图中每个节点代表一个商品，图中的边代表用户点击头结点对应的商品后点击了尾结点对应的商品。
  * 根据节点被访问的次数来给边一个正则化的权重，计算方式为这条边出现的次数除以头结点的出度，然后将所有商品节点整合成一张会话图。

* **门控RNN**
  * 提取节点邻居的潜在特征向量并作为GNN的输入。
  * 更新门和重置门决定保留特征向量的哪些信息，然后在重置门的控制下，根据前一状态和当前状态来构建候补状态。
  * 在更新门的控制下，以前的隐藏状态和候选状态的结合产生节点的最终状态。
  * 更新会话图的所有节点直到收敛，获得会话图中所有节点的最终的潜在特征向量。
* **会话嵌入**
  * 将会话序列的最后一次点击作为局部特征，表示当前兴趣。
  * 通过聚合所有会话序列中的节点向量获得会话图的全局特征，考虑到不同节点的信息有不同的优先级，采用软注意力机制来更好的表示长期偏好。
  * 通过线性转换将局部特征和全局特征整合为混合特征，即同时考虑当前兴趣和长期偏好。
* **产生推荐**
  * 对所有候补节点，将节点向量和会话表示的乘积作为分数。
  * 应用softmax函数获得模型的输出向量。

#### 模型训练

* 损失函数定义为预测和真实值的交叉熵。
* 采用基于时间的反向传播来训练模型。
* 由于回话的长度一般较短，建议采用相对小的训练步数防止过拟合。



## 实验

#### 数据集

* Yoochoose

* Diginetica

  为了公平对比，去除了两个数据集中长度为1的序列和出现次数少于5次的商品。将Yoochoose的近64分之一和近四分之一以及Diginetica作为三个比较的数据集，将数据集随后的日子中的会话作为测试集。

#### 对比方法

* **POP**
* **s-pop**
* **Item-KNN**
* **BPR-MF**
* **FPMC**
* **GRU4REC**
* **NARM**
* **STAMP**

#### 评价指标

* P@20
* MRR@20

#### 实验结果

​	在三个数据集两个评价标准的实验中，SR-GNN方法都表现最佳；传统方法如POP和S-POP都表现很差，这两个简单的模型仅基于连续商品，但S-POP表现仍优于POP、BPR-MF和FPMC，证实了会话上下文信息的重要性；Item-KNN表现优于基于马尔科夫链的FPMC，证实了传统的基于马尔科夫链的算法的连续商品独立性假设是错误的。

​	至于神经网络方法，如NARM和STAMP，表现优于传统方法，证实了深度学习适用于这一领域。LSTM模型如GRU4REC和NARM使用循环单元捕捉用户的整体兴趣，而STAMP通过利用最后一次点击来提升短期兴趣。



